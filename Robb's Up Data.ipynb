{
 "metadata": {
  "name": "",
  "signature": "sha256:84a72b978b28b4b8eb1126e580864306a56a6d4f441aad1ca1c5526e8d8d3e5d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "I'm going to import my Withings weight data and run a time series analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Setup the data to be imported"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import statsmodels.api as sm\n",
      "\n",
      "table = pd.read_csv('Activity.csv',parse_dates=[0],keep_date_col=True)\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We should now have the CSV stored in the table variable.  Let's look at the first 15 rows and see what's there"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table.head(15)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's see some statistics on the overall data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next I'll create my own calculated field for % lean mass and % body fat"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import datetime\n",
      "str(datetime.timedelta(seconds=table['TotalActiveTimeInSeconds'][0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#table['TotalTimeTrackedInMin'] = datetime.timedelta(seconds=table['TotalActiveTimeInSeconds']) + datetime.timedelta(seconds=table['TotalInactiveTimeInSeconds'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table.head(15)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Plotting"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's see what the data looks like on a plot"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Area Plot"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Not very interesting. Let's focus on just lean and fat mass on an area plot"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table[['TotalActiveTimeInSeconds','TotalInactiveTimeInSeconds']].plot(kind='area')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Area, Bar, Barh Plots"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's try out all the plot types"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table.plot(kind='area')\n",
      "table.plot(kind='bar')\n",
      "table.plot(kind='barh')\n",
      "#table['% body fat'].plot(kind='pie',y='% lean mass')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Scatter"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a good gauge of how consistent my band maps steps to mileage.  It looks like there is some variance.\n",
      "\n",
      "Definition: A graph in which the values of two variables are plotted along two axes, the pattern of the resulting points revealing any correlation present."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table.plot(kind='scatter',x='DistanceCoveredMI',y='TotalSteps')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Hexagonal Binning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I don't really have enough overlapping data for this type of plot, but here it is anyways\n",
      "\n",
      "Definition:\n",
      "Hexagon binning is a form of bivariate histogram useful for visualizing the structure\n",
      "in datasets with large n. The underlying concept of hexagon binning is\n",
      "extremely simple;\n",
      "1. the xy plane over the set (range(x), range(y)) is tessellated by a regular\n",
      "grid of hexagons.\n",
      "2. the number of points falling in each hexagon are counted and stored in a\n",
      "data structure\n",
      "3. the hexagons with count > 0 are plotted using a color ramp or varying\n",
      "the radius of the hexagon in proportion to the counts.\n",
      "\n",
      "Additional information http://www.meccanismocomplesso.org/en/hexagonal-binning/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table.plot(kind='hexbin',x='DistanceCoveredMI',y='TotalSteps')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Scatter Plot Matrix"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's try a Scatter Plot Matrix http://pandas.pydata.org/pandas-docs/stable/visualization.html#visualization-scatter-matrix\n",
      "Scatterplot matrices are a great way to roughly determine if you have a linear correlation between multiple variables. This is particularly helpful in pinpointing specific variables that might have similar correlations to your genomic or proteomic data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.scatter_matrix(table, alpha=0.2, figsize=(6, 6), diagonal='kde')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas.tools.plotting as pdplt\n",
      "#nodateTable = table.copy()\n",
      "#del nodateTable['Date']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Lag Plot"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lag plots are used to check if a data set or time series is random. Random data should not exhibit any structure in the lag plot. Non-random structure implies that the underlying data are not random."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pdplt.lag_plot(table['TotalSteps'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Auto Correlation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Autocorrelation plots are often used for checking randomness in time series. This is done by computing autocorrelations for data values at varying time lags. If time series is random, such autocorrelations should be near zero for any and all time-lag separations. If time series is non-random then one or more of the autocorrelations will be significantly non-zero. The horizontal lines displayed in the plot correspond to 95% and 99% confidence bands. The dashed line is 99% confidence band."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pdplt.autocorrelation_plot(table['TotalSteps'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Bootstrap Plot"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Bootstrap plots are used to visually assess the uncertainty of a statistic, such as mean, median, midrange, etc. A random subset of a specified size is selected from a data set, the statistic in question is computed for this subset and the process is repeated a specified number of times. Resulting plots and histograms are what constitutes the bootstrap plot."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pdplt.bootstrap_plot(table['TotalSteps'], size=50, samples=500, color='grey')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "RadViz"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Works best when you have a few common values across the data to group by.  If I lower the precision of the data by rounding I'll get better results, but this data really means nothing\n",
      "\n",
      "RadViz is a way of visualizing multi-variate data. It is based on a simple spring tension minimization algorithm. Basically you set up a bunch of points in a plane. In our case they are equally spaced on a unit circle. Each point represents a single attribute. You then pretend that each sample in the data set is attached to each of these points by a spring, the stiffness of which is proportional to the numerical value of that attribute (they are normalized to unit interval). The point in the plane, where our sample settles to (where the forces acting on our sample are at an equilibrium) is where a dot representing our sample will be drawn. Depending on which class that sample belongs it will be colored differently. http://pandas.pydata.org/pandas-docs/stable/visualization.html#visualization-radviz"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#roundedTable = table.copy()\n",
      "#roundedTable['TotalSteps'] = np.round(roundedTable['TotalSteps'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#pdplt.radviz(roundedTable.sort(ascending=False), 'TotalSteps')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Timeseries and Predictive Forecasting"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are going to use some models commonly used in econometrics. Which will use historical data to predict future data. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Auto Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. I had to normalize the date ranges so the times all start at midnight instead of when they were actually taken.\n",
      "2. I turned the Date column into the index\n",
      "3. Changing the index lost the Date column so I had to add it back\n",
      "4. Once I had the dates as the index I could resample the data and fill in any gaps where a measurement wasn't taken.  I just use the previous measurement for that day and assume no change\n",
      "\n",
      "Definition: In statistics and signal processing, an autoregressive (AR) model is a representation of a type of random process; as such, it describes certain time-varying processes in nature, economics, etc. The autoregressive model specifies that the output variable depends linearly on its own previous values. It is a special case of the more general ARMA model of time series. http://en.wikipedia.org/wiki/Autoregressive_model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "treatedTable = table.copy()\n",
      "#print(treatedTable.index)\n",
      "tempIndex = treatedTable.index\n",
      "treatedTable['Date'] = pd.DatetimeIndex(treatedTable['Date']).normalize()\n",
      "#treatedTable = treatedTable.sort(columns=['Date'],ascending=True)\n",
      "treatedTable = treatedTable.set_index(pd.DatetimeIndex(treatedTable['Date']),drop=False)\n",
      "treatedTable = treatedTable.resample('D',fill_method='pad')\n",
      "#print(treatedTable)\n",
      "treatedTable['Date'] = treatedTable.index\n",
      "treatedTable = treatedTable.set_index(pd.DatetimeIndex(treatedTable['Date']),drop=False)\n",
      "print(treatedTable.head(15))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ar = sm.tsa.AR(np.round(table['TotalSteps']), dates=table['Date'], freq='D').fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ar.predict('2015-04-08','2015-12-31').plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Auto Regression Moving Average (ARMA)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition to the Regression for past time periods we can also add in the a moving average to create an AR MA or ARMA model. This looks for changed in seasonality and can project them into the future. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import statsmodels.api as sm\n",
      "import matplotlib.pyplot as plt\n",
      "from statsmodels.sandbox.regression.predstd import wls_prediction_std"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here's what the actual data plot looks like"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table['TotalSteps'].plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here's what my forecasted weight will be over the period specified.  The gray area is the uncertainty, which to me looks pretty large.\n",
      "\n",
      "The first number is the order for the autoreqressive part and the second is the order for the moving average. Playing with those numbers gives essentially the same result with small differences"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arma_mod = sm.tsa.ARMA(table['TotalSteps'],(3,2), dates=table['Date'],freq='D').fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = arma_mod.plot_predict('2015-04-18','2015-12-31')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It looks like statistically I'm going to gain a pound every year"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}